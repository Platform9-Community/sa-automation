set export

kubeconfig := env_var_or_default("KUBECONFIG", "path_to_a_kubeconfig")
kube_context := env_var_or_default("KUBE_CONTEXT", "default")

# Customize any of the below
namespace := "rook-ceph"
log_level := "INFO"
ceph_cluster_name := "rook-ceph"
chart_name := "rook-ceph"
chart_repo := "rook-release"
chart_version := "v1.11.7"
version_safe := replace(chart_version,'.','-')
repo_url := "https://charts.rook.io/release"
monitoring_enabled := "false"
rbd_enabled := "true"
cephfs_enabled := "true"
crds_enabled := "true"
# below lines are only required for multi homed cluster
# https://github.com/rook/rook/blob/master/Documentation/CRDs/Cluster/ceph-cluster-crd.md#ceph-public-and-cluster-networks
multi_homed_networks := "false"
ceph_public_network := "10.10.10.0/24"
ceph_cluster_network := "10.10.20.0/24"
# end customizations

_helm_common := '--namespace $namespace --kubeconfig $kubeconfig --kube-context $kube_context'

_helm_args := '$chart_name $chart_repo/$chart_name \
  --version $chart_version \
  --set "crds.enabled=$crds_enabled" \
  --set "monitoring.enabled=$monitoring_enabled" \
  --set "logLevel=$log_level" \
  --set "enableRbdDriver=$rbd_enabled" \
  --set "enableCephfsDriver=$cephfs_enabled" \
  --values values_$version_safe.yaml \
  --values values_tolerations.yaml \
'

_kubectl_common := "--context $kube_context --kubeconfig $kubeconfig"

_bash := "#!/usr/bin/env bash\nset -vuxo pipefail"

_sh := "just --no-highlight _exec_sh"

_k := "kubectl"

_default:
  @just --list --unsorted

_exec_sh *ARGS:
  @{{_bash}}
  {{ARGS}}

setup:
  @{{_sh}} "helm repo add {{chart_repo}} {{repo_url}} && helm repo update"

generate_values:
  @{{_sh}} "if [[ -f values_{{version_safe}}.yaml ]]; then cp values_{{version_safe}}.yaml values_{{version_safe}}.yaml.$(date '+%Y%m%d_%s'); fi"
  @{{_sh}} "helm show values {{chart_repo}}/{{chart_name}} --version \
    {{chart_version}} > values_{{version_safe}}.yaml"

search_chart_versions:
  @{{_sh}} "helm search repo -l {{chart_repo}}/{{chart_name}}"

apply_labels:
  @{{_sh}} "for master in $(kubectl get nodes --selector=node-role.kubernetes.io/master \
    {{_kubectl_common}} -o jsonpath='{$.items[*].metadata.name}') ; \
    do echo \$master ; \
    kubectl label {{_kubectl_common}} nodes \$master role=ceph-operator-node --overwrite=true || true ; \
  done"
  @{{_sh}} "for worker in $(kubectl get nodes --selector=node-role.kubernetes.io/worker \
    {{_kubectl_common}} -o jsonpath='{$.items[*].metadata.name}') ; \
    do echo \$worker ; \
    kubectl label {{_kubectl_common}} nodes \$worker role=ceph-storage-node --overwrite=true || true ; \
  done"

remove_labels:
  @{{_sh}} "for master in $(kubectl get nodes --selector=node-role.kubernetes.io/master \
    {{_kubectl_common}} -o jsonpath='{$.items[*].metadata.name}') ; \
    do echo \$master ; \
    kubectl label {{_kubectl_common}} nodes \$master role- --overwrite=true || true ; \
  done"
  @{{_sh}} "for worker in $(kubectl get nodes --selector=node-role.kubernetes.io/worker \
    {{_kubectl_common}} -o jsonpath='{$.items[*].metadata.name}') ; \
    do echo \$worker ; \
    kubectl label {{_kubectl_common}} nodes \$worker role- --overwrite=true || true ; \
  done"

create_configmap:
  @{{_sh}} "if [[ \"$multi_homed_networks\" == \"true\" ]]; then \
    envsubst < rook-config-override.yaml.tmpl | kubectl apply \
    --namespace {{namespace}} \
    {{_kubectl_common}} \
    -f - ; \
    fi"

delete_configmap:
  @{{_sh}} "envsubst < rook-config-override.yaml.tmpl | kubectl delete \
    --namespace {{namespace}} {{_kubectl_common}} -f -"

create_namespace:
  @echo "Namespace may already exist, in which case ignore errors"
  @{{_sh}} "kubectl create ns {{namespace}} {{_kubectl_common}} || true"

install: create_namespace apply_labels create_configmap
  @{{_sh}} "helm install {{_helm_args}} {{_helm_common}}"

upgrade:
  @{{_sh}} "helm upgrade {{_helm_args}} {{_helm_common}}"

uninstall: remove_labels
  @{{_sh}} "helm uninstall {{chart_name}} {{_helm_common}} || true"
  @{{_sh}} "kubectl delete namespace {{namespace}} {{_kubectl_common}} --force=true || true"

destroy_crds:
  @{{_sh}} "for cr in $(kubectl {{_kubectl_common}} get crd | \
    grep ceph.rook.io | awk '{printf "%s ",$1}') ; \
    do kubectl {{_kubectl_common}} delete crd \$cr ; \
  done"
  @{{_sh}} "kubectl {{_kubectl_common}} delete crd objectbuckets.objectbucket.io || true"
  @{{_sh}} "kubectl {{_kubectl_common}} delete crd objectbucketclaims.objectbucket.io || true"

list:
  @{{_sh}} "helm list --filter {{chart_name}} --all-namespaces --kubeconfig {{kubeconfig}} \
    --kube-context {{kube_context}}"
  @{{_sh}} "kubectl {{_kubectl_common}} get pods -l 'app=rook-ceph-operator' -o wide -A"
