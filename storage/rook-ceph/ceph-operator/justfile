set export

kubeconfig := env_var_or_default("KUBECONFIG", "path_to_a_kubeconfig")
kube_context := env_var_or_default("KUBE_CONTEXT", "default")
namespace := "rook-ceph"
log_level := "INFO"
ceph_cluster_name := "rook-ceph"
chart_name := "rook-ceph"
chart_repo := "rook-release"
chart_version := "v1.11.1"
repo_url := "https://charts.rook.io/release"
monitoring_enabled := "false"
rbd_enabled := "true"
cephfs_enabled := "true"
crds_enabled := "true"
# below 3 lines are only for multi homed cluster
multi_homed_networks := "false"
ceph_public_network := "10.10.10.0/24"
ceph_cluster_network := "10.10.20.0/24"

_helm_common := '--namespace $namespace --kubeconfig $kubeconfig --kube-context $kube_context'

_helm_args := '$chart_name $chart_repo/$chart_name \
  --namespace $namespace \
  --kubeconfig $kubeconfig \
  --kube-context $kube_context \
  --version $chart_version \
  --set "crds.enabled=$crds_enabled" \
  --set "monitoring.enabled=$monitoring_enabled" \
  --set "logLevel=$log_level" \
  --set "enableRbdDriver=$rbd_enabled" \
  --set "enableCephfsDriver=$cephfs_enabled" \
  --values values_overrides.yaml \
'

_kubectl_common := "--context $kube_context --kubeconfig $kubeconfig"

_bash := "#!/usr/bin/env bash\nset -vuxo pipefail"

_sh := "just --no-highlight _exec_sh"

_k := "kubectl"

_default:
  @just --list --unsorted

_exec_sh *ARGS:
  @{{_bash}}
  {{ARGS}}

setup:
  @{{_sh}} "helm repo add {{chart_repo}} {{repo_url}} && helm repo update"

generate_values:
  @{{_sh}} "helm show values {{chart_repo}}/{{chart_name}} --version \
    {{chart_version}} > values.yaml"

search_chart_versions:
  @{{_sh}} "helm search repo -l {{chart_name}}"

render_templates:
  @{{_sh}} "helm template {{_helm_args}} > template.yaml"

apply_labels:
  @{{_sh}} "for master in $(kubectl get nodes --selector=node-role.kubernetes.io/master \
    {{_kubectl_common}} -o jsonpath='{$.items[*].metadata.name}') ; \
    do echo \$master ; \
    kubectl label {{_kubectl_common}} nodes \$master role=ceph-operator-node || true ; \
  done"
  @{{_sh}} "for worker in $(kubectl get nodes --selector=node-role.kubernetes.io/worker \
    {{_kubectl_common}} -o jsonpath='{$.items[*].metadata.name}') ; \
    do echo \$worker ; \
    kubectl label {{_kubectl_common}} nodes \$worker role=ceph-storage-node || true ; \
  done"

create_configmap:
  @{{_sh}} "if [[ \"$multi_homed_networks\" == \"true\" ]]; then \
    envsubst < rook-config-override.yaml.tmpl | kubectl apply \
    --namespace {{namespace}} \
    {{_kubectl_common}} \
    -f - ; \
    fi"

delete_configmap:
  @{{_sh}} "envsubst < rook-config-override.yaml.tmpl | kubectl delete \
    --namespace {{namespace}} {{_kubectl_common}} -f -"

create_namespace:
  @echo "Namespace may already exist, in which case ignore errors"
  @{{_sh}} "kubectl create ns {{namespace}} {{_kubectl_common}} || true"

install: create_namespace apply_labels create_configmap
  @{{_sh}} "helm install {{_helm_common}} {{_helm_args}}"

upgrade:
  @{{_sh}} "helm upgrade {{_helm_common}} {{_helm_args}}"

uninstall:
  @{{_sh}} "helm uninstall {{chart_name}} {{_helm_common}} || true"
  @{{_sh}} "kubectl delete namespace {{namespace}} {{_kubectl_common}} --force=true || true"

destroy_crds:
  @{{_sh}} "for cr in $(kubectl {{_kubectl_common}} get crd | \
    grep ceph.rook.io | awk '{printf "%s ",$1}') ; \
    do kubectl {{_kubectl_common}} delete crd \$cr ; \
  done"
  @{{_sh}} "kubectl {{_kubectl_common}} delete crd objectbuckets.objectbucket.io || true"
  @{{_sh}} "kubectl {{_kubectl_common}} delete crd objectbucketclaims.objectbucket.io || true"

list:
  @{{_sh}} "helm list --filter {{chart_name}} --all-namespaces --kubeconfig {{kubeconfig}} \
    --kube-context {{kube_context}}"
  @{{_sh}} "kubectl {{_kubectl_common}} get pods -l 'app=rook-ceph-operator' -o wide -A"
